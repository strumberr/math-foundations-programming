x = np.linalg.solve(coefficient_array, constant_array)
y = x[1]
z = x[2]
x = x[0]
print(f"x: {x}, y: {y}, z: {z}")







for iteration in range(0, len(gaussian_array)):

        for i in range(iteration+1, len(gaussian_array)):

            # print(f"iteration: {iteration}")

            factor = coefficient_array[i][iteration] / coefficient_array[iteration][iteration]

            for j in range(len(coefficient_array[i])):

                coefficient_array[i][j] -= factor * coefficient_array[iteration][j]

            constant_array[i] -= factor * constant_array[iteration]







    def residual_error_single_iteration(self, coefficient_array, constant_array, solution_vector, iteration):
        lhs = 0
        for j in range(len(coefficient_array[iteration])):
            lhs += coefficient_array[iteration][j] * solution_vector[j]
        rhs = constant_array[iteration]
        residual_error = abs(lhs - rhs)
        return residual_error
    
    def absolute_error_single_iteration(self, real_solution, estimated_solution, iteration):
        absolute_error = abs(real_solution[iteration] - estimated_solution[iteration])
        return absolute_error
    





def jacobi_method(self, coefficient_array, constant_array, max_iterations=1000, eps=1e-9):
        
        current_value_array = []
        n = len(coefficient_array)
        x = [0 for i in range(n)]
        x_new = x.copy()
        k = 0

        while k < max_iterations:
            for i in range(n):
                sigma = 0
                for j in range(n):
                    if j != i:
                        sigma += coefficient_array[i][j] * x[j]
                x_new[i] = (constant_array[i] - sigma) / coefficient_array[i][i]
            k += 1
            x = x_new.copy()
            current_value_array.append(x_new.copy())

        return x_new, k, current_value_array








diagonal_matrix = []

        for i in range(len(self.matrix)):
            diagonal_matrix.append([0 for i in range(len(self.matrix))])

        for i in range(len(self.matrix)):
            diagonal_matrix[i][i] = self.matrix[i][i]

        for el in 














 def cubic_interpolate(self, x0=None, x=None, y=None):

        if x0 is None: x0 = self.x0
        if x is None: x = self.x
        if y is None: y = self.y

        xdiff = np.diff(x)
        dydx = np.diff(y) / xdiff

        n = size = len(x)

        w = np.empty(n-1)
        z = np.empty(n)

        w[0] = 0.
        z[0] = 0.

        # this here solves a thing called the tridiagonal 
        # system of equations to find the second derivatives at each point
        for i in range(1, n-1):
            m = xdiff[i-1] * (2 - w[i-1]) + 2 * xdiff[i]
            w[i] = xdiff[i] / m
            z[i] = (6 * (dydx[i] - dydx[i-1]) - xdiff[i-1] * z[i-1]) / m

        z[-1] = 0.

        for i in range(n-2, -1, -1):
            z[i] -= w[i] * z[i+1]

        index = np.clip(x.searchsorted(x0), 1, size-1) 

        # this here finds the index of the element in x that is closest to x0
        xi1, xi0 = x[index], x[index-1]
        yi1, yi0 = y[index], y[index-1]
        zi1, zi0 = z[index], z[index-1]
        hi1 = xi1 - xi0

        # this here is the cubic interpolation formula
        f0 = (zi0 * (xi1 - x0) ** 3) / (6 * hi1) + \
            (zi1 * (x0 - xi0) ** 3) / (6 * hi1) + \
            ((yi1 / hi1) - (zi1 * hi1 / 6)) * (x0 - xi0) + \
            ((yi0 / hi1) - (zi0 * hi1 / 6)) * (xi1 - x0)
        

        return f0
    





    loss_function = 0
        for i in range(len(x)):
            loss_function += (y[i] - (c0 * x[i] + c1))**2